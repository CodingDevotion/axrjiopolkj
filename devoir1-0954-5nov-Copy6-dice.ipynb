{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travail 1\n",
    "\n",
    "### Dans le cadre du cours IFT3700 - Science des données\n",
    "\n",
    "Effectué par <br> Alexandre Chartrand,<br> Lauranne Deaudelin, <br> Amélie Lacombe Robillard, et <br> Stéphane Verville-Vohl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binary Partition -> Plugger la matrice de dissimilarité\n",
    "- ISOMAP -> Trouver un moyen de calculer les bon eigenvectors avec la distance custom\n",
    "- Mettre des scores à chacun des 5 algorithmes pour pouvoir comparer\n",
    "\n",
    "- Doubler tout, pour faire Euclédian (en cours)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraires à installer \n",
    "Il faut s'arrurer que la librairie pyclustering est installée.  \n",
    "https://pypi.org/project/pyclustering/0.8.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 1000\n",
    "TEST_SIZE = 25\n",
    "\n",
    "def extract_data(dataset, size):\n",
    "    data = open(dataset)\n",
    "    reader = csv.reader(data)\n",
    "    data_points = []\n",
    "    count = 0\n",
    "    for row in reader:\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        elif count <= size:\n",
    "            data_points.append(row)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    data.close()\n",
    "\n",
    "    # Convert data in numpy array, with int type\n",
    "    ndarray_dataset = np.array(data_points).astype(int)\n",
    "    \n",
    "    # Data input\n",
    "    inputs = ndarray_dataset[:,1:]\n",
    "    # Target vector (label vector)\n",
    "    targets = ndarray_dataset[:,0]\n",
    "    \n",
    "    return (inputs, targets)\n",
    "\n",
    "training_data = extract_data('mnist_train.csv', TRAINING_SIZE)\n",
    "training_inputs = training_data[0]\n",
    "training_targets = training_data[1]\n",
    "\n",
    "test_data = extract_data('mnist_test.csv', TEST_SIZE)\n",
    "test_inputs = test_data[0]\n",
    "test_targets = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_similarity_measure(x,y):\n",
    "    return min_translation_distance(x,y)\n",
    "    #return np.sum(abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "#### Helper functions ######\n",
    "\n",
    "# Crop a matrix according to margins of format (top, bottom, left, right)\n",
    "def crop_matrix(x, margins):\n",
    "    return x[margins[0]:x.shape[0]-margins[1],margins[2]:x.shape[1]-margins[3]]\n",
    "\n",
    "# Pad a matrix with zeros according to a margin of format (top, bottom, left, right)\n",
    "def pad_matrix(x, margins):\n",
    "    x_tilda = np.zeros((x.shape[0]+margins[0]+margins[1], x.shape[1]+margins[2]+margins[3]), dtype=int)\n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[1]) :\n",
    "            x_tilda[i+margins[0],j+margins[2]] = x[i,j]\n",
    "    return x_tilda\n",
    "\n",
    "# TO REMOVE\n",
    "def euclidean_distance(x,y) :\n",
    "    return dist.dice(x, y)\n",
    "\n",
    "##### Custom similarity measure based on smallest translation distance\n",
    "#Return the smallest translation distance of all possible translations of a number of pixels d or smaller\n",
    "# in all directions (top, bottom, left, right and diagonals) \n",
    "def min_translation_distance(x, y, d=1):\n",
    " \n",
    "    #This should be a hyper parameter but it would change the function signature\n",
    "    #d = 1\n",
    "    \n",
    "    transform_margins = []\n",
    "    for i in range(1, d+1) :\n",
    "        transform_margins.extend([[d-i,d+i,d,d], #top\n",
    "                                  [d+i, d-i, d,d], #bottom\n",
    "                                  [d, d, d-i, d+i], #left \n",
    "                                  [d, d, d+i, d-i], #right\n",
    "                                  [d-i, d+i, d-i, d+i], #top-left\n",
    "                                  [d-i, d+i, d+i, d-i], #top-right\n",
    "                                  [d+i, d-i, d-i, d+i], #bottom-left\n",
    "                                  [d+i, d-i, d+i, d-i]]) #bottom-right\n",
    "           \n",
    "\n",
    "    \n",
    "    #We assume that we are working with mnist data, or else reshaping dimensions are not valid\n",
    "    if (x.size != 784) or (x.size != y.size) :\n",
    "        print(\"invalid x or y\")\n",
    "\n",
    "    #Reshape into matrix for ease \n",
    "    #y_matrix = y.reshape(28,28)\n",
    "    \n",
    "    #Test without translation : \n",
    "    #smallest_dist = euclidean_distance(x.reshape(28,28), y_matrix)\n",
    "    smallest_dist = euclidean_distance(x , y)\n",
    "\n",
    "    \n",
    "    #We pad x with white pixels all around. \n",
    "    #This ensure that we will always be working with same size matrix,\n",
    "    # and won't affect the overall distance (as the distance between two white pixels will be 0 and won't affect the total distance)\n",
    "    x_padded = pad_matrix(x.reshape(28,28), [d,d,d,d])\n",
    "\n",
    "    #Test all translations and keep the one with the smallest distance\n",
    "    for i in range(0, len(transform_margins)) :\n",
    "        #distance = euclidean_distance(crop_matrix(x_padded, transform_margins[i]), y_matrix)\n",
    "        distance = euclidean_distance(crop_matrix(x_padded, transform_margins[i]).reshape(1, 784), y)\n",
    "        \n",
    "        if(distance < smallest_dist) :\n",
    "            smallest_dist = distance\n",
    "        \n",
    "    return smallest_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_similarity_measure(x, y):\n",
    "    return np.sqrt(np.dot(x,x) - 2 * np.dot(x,y) + np.dot(y,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissimilarity Matrix with the custom measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distance_matrix(data, distance_type):\n",
    "    nb_examples = data.shape[0]\n",
    "    distance_ndarray = np.zeros((nb_examples,nb_examples))\n",
    "    \n",
    "    for i in range(nb_examples):\n",
    "        for j in range(nb_examples):\n",
    "            if distance_type is 'euclidean':\n",
    "                distance_ndarray[i][j] = euclidean_similarity_measure(data[i],data[j])\n",
    "            elif distance_type is 'custom':\n",
    "                distance_ndarray[i][j] = custom_similarity_measure(data[i],data[j])\n",
    "            else:\n",
    "                print(\"accepted values for argument 'distance_type': 'euclidean','custom'\")\n",
    "                return\n",
    "    return distance_ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute dissimilarity matrices on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 919.5779030323029 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "custom_distance_matrix = generate_distance_matrix(training_inputs, 'custom')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "euclidean_distance_matrix = generate_distance_matrix(training_inputs, 'euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-medoid Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Euclidean distance results:\n",
      "\n",
      "Training dataset size: 1000\n",
      "\n",
      "Number of medoids: 10\n",
      "Cluster mapping: [(0, 5), (1, 0), (2, 9), (3, 1), (4, 9), (5, 2), (6, 1), (7, 3), (8, 1), (9, 9)]\n",
      "Euclidean prediction score: 0.48\n",
      "Euclidean homogeneity: 0.4203948192946918\n",
      "Euclidean cluster completeness: 0.8085989114317371\n",
      "\n",
      "Custom distance results:\n",
      "\n",
      "Training dataset size: 1000\n",
      "\n",
      "Number of medoids: 10\n",
      "Cluster mapping: [(0, 5), (1, 0), (2, 4), (3, 1), (4, 9), (5, 0), (6, 1), (7, 3), (8, 1), (9, 4)]\n",
      "Custom prediction score: 0.43999999999999995\n",
      "Custom homogeneity: 0.5898269368309494\n",
      "Custom cluster completeness: 0.7560253108406848\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from sklearn import metrics\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "\n",
    "K = 10\n",
    "\n",
    "# Initialization of medoids\n",
    "initial_medoids = [i for i in range(K)]\n",
    "\n",
    "def map_medoid_labels(medoids):\n",
    "    medoid_labels = []\n",
    "    for i,medoid in enumerate(medoids):\n",
    "        medoid_labels.append((i, training_targets[medoid]))\n",
    "    return medoid_labels\n",
    "    \n",
    "    \n",
    "def kmedoid_predict(medoids, distance_type):\n",
    "    predictions = []\n",
    "    # For all test inputs\n",
    "    for row in test_inputs:\n",
    "        min_arg = (404, float('inf'))\n",
    "        for medoid in medoids:\n",
    "            # Find the closest medoid\n",
    "            if distance_type is 'euclidean':\n",
    "                candidate_distance = euclidean_similarity_measure(row, training_inputs[medoid])\n",
    "            elif distance_type is 'custom':\n",
    "                candidate_distance = custom_similarity_measure(row, training_inputs[medoid])\n",
    "            if candidate_distance < min_arg[1]:\n",
    "                min_arg = (medoid, candidate_distance)\n",
    "        # Return the nearest medoid's label\n",
    "        predictions.append(training_targets[min_arg[0]])\n",
    "        ndarray_predictions = np.array(predictions).astype(int)\n",
    "    return ndarray_predictions\n",
    "\n",
    "\n",
    "def kmedoid_prediction_score(predictions):\n",
    "    error = 0\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        target = test_targets[i]\n",
    "        if prediction != target:\n",
    "            error += 1\n",
    "    return 1 - error/predictions.shape[0]\n",
    "\n",
    "\n",
    "# ================ Euclidean k-Medoid ======================\n",
    "euclidean_kmedoids = kmedoids(euclidean_distance_matrix, initial_medoids, data_type='distance_matrix')\n",
    "euclidean_kmedoids.process()\n",
    "euclidean_clusters = euclidean_kmedoids.get_clusters()\n",
    "euclidean_medoids = euclidean_kmedoids.get_medoids()\n",
    "euclidean_predictions = kmedoid_predict(euclidean_medoids, 'euclidean')\n",
    "euclidean_kmedoid_score = kmedoid_prediction_score(euclidean_predictions)\n",
    "\n",
    "print('\\nEuclidean distance results:')\n",
    "print(\"\\nTraining dataset size:\", TRAINING_SIZE)\n",
    "print(\"\\nNumber of medoids:\", K)\n",
    "print(\"Cluster mapping:\", map_medoid_labels(euclidean_medoids))\n",
    "print(\"Euclidean prediction score:\", euclidean_kmedoid_score)\n",
    "print(\"Euclidean homogeneity:\", metrics.homogeneity_score(test_targets, euclidean_predictions)  )\n",
    "print(\"Euclidean cluster completeness:\", metrics.completeness_score(test_targets, euclidean_predictions))\n",
    "                             \n",
    "# ==================== Custom k-Medoid =====================\n",
    "custom_kmedoids = kmedoids(custom_distance_matrix, initial_medoids, data_type='distance_matrix')\n",
    "custom_kmedoids.process()\n",
    "custom_clusters = custom_kmedoids.get_clusters()\n",
    "custom_medoids = custom_kmedoids.get_medoids()                             \n",
    "custom_predictions = kmedoid_predict(custom_medoids, 'custom')\n",
    "custom_kmedoid_score = kmedoid_prediction_score(custom_predictions)\n",
    "\n",
    "print('\\nCustom distance results:')\n",
    "print(\"\\nTraining dataset size:\", TRAINING_SIZE)\n",
    "print(\"\\nNumber of medoids:\", K)\n",
    "print(\"Cluster mapping:\", map_medoid_labels(custom_medoids))\n",
    "print(\"Custom prediction score:\", custom_kmedoid_score)\n",
    "print(\"Custom homogeneity:\", metrics.homogeneity_score(test_targets, custom_predictions))\n",
    "print(\"Custom cluster completeness:\", metrics.completeness_score(test_targets, custom_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.8936104774475098 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary partition Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "binary_partition = tree.DecisionTreeClassifier()\n",
    "binary_partition = binary_partition.fit(X, Y)\n",
    "\n",
    "print(binary_partition.decision_path(X))\n",
    "print(binary_partition.score(X,Y))\n",
    "binary_partition.get_params()\n",
    "\n",
    "# TODO : calculer l'impureté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCoA  Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "#PCOA avec euclidien built-in\n",
    "pcoa_builtin = MDS(n_components=2, dissimilarity='euclidean')\n",
    "builtin_transformed = pcoa_builtin.fit_transform(training_inputs)\n",
    "\n",
    "#PCOA avec matrice de dissimilarité euclidienne\n",
    "pcoa_euclid = MDS(n_components=2, dissimilarity='precomputed')\n",
    "euclid_transformed = pcoa_euclid.fit_transform(euclidean_distance_matrix)\n",
    "\n",
    "#PCOA avec matrice de dissimilarité custom\n",
    "pcoa_custom = MDS(n_components=2, dissimilarity='precomputed')\n",
    "custom_transformed = pcoa_custom.fit_transform(custom_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_by_label(inputs, targets, label) :\n",
    "    return(inputs[np.where(targets[:] == label)[0], :])\n",
    "    \n",
    "def plot_graph_by_labels(inputs, targets) :\n",
    "    colors = ['b', 'r', 'g', 'y', 'c', 'k', 'darkorange', 'lightcoral', 'lime', 'grey']\n",
    "    for i in range(0, 10) :\n",
    "            extracted = extract_data_by_label(inputs, targets, i)\n",
    "            plt.scatter(extracted[:,0], extracted[:,1], 8, colors[i])\n",
    "    pylab.xlabel('x')\n",
    "    pylab.ylabel('y')\n",
    "    plt.title('MNIST dans l\\'espace 2D avec PCoA custom')\n",
    "    plt.show()\n",
    "\n",
    "plot_graph_by_labels(builtin_transformed, training_targets)\n",
    "\n",
    "plot_graph_by_labels(euclid_transformed, training_targets)\n",
    "\n",
    "plot_graph_by_labels(custom_transformed, training_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISOMAP Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ISOMAP Algorithm\n",
    "\n",
    "from sklearn.manifold import Isomap\n",
    "ISOMAP = Isomap(n_neighbors=1, n_components=2)\n",
    "ISOMAP.fit(inputs, targets)\n",
    "ISOMAP.get_params()\n",
    "print(ISOMAP.dist_matrix_)\n",
    "\n",
    "# TODO : calculer l'impureté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1000\n",
      "Neighbours taken into account: 5\n",
      "Euclidean score: 0.72\n",
      "Custom score: 0.56\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "neighbourinos = 5\n",
    "\n",
    "KNN_euclid = KNeighborsClassifier(n_neighbors=neighbourinos,  metric='euclidean')\n",
    "KNN_custom = KNeighborsClassifier(n_neighbors=neighbourinos, algorithm='ball_tree', metric=custom_similarity_measure)\n",
    "\n",
    "KNN_euclid.fit(training_inputs, training_targets)\n",
    "KNN_custom.fit(training_inputs, training_targets)\n",
    "\n",
    "score_euclid = accuracy_score(KNN_euclid.predict(test_inputs), test_targets)\n",
    "score_custom = accuracy_score(KNN_custom.predict(test_inputs), test_targets)\n",
    "\n",
    "print(\"Training dataset size:\", TRAINING_SIZE)\n",
    "print(\"Neighbours taken into account:\", neighbourinos)\n",
    "print(\"Euclidean score:\", score_euclid)\n",
    "print(\"Custom score:\", score_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.02421498298645 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
